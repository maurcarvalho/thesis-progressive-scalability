\pagebreak
\section{G3: Design for Progressive Scalability}
\label{sec:g3-design-progressive-scalability}

This section presents G3, which focuses on designing modular monoliths so that scalability is achieved progressively rather than through premature distribution. In this dissertation, \emph{progressive scalability} is defined as the capacity of a modular monolith to accommodate increasing load, data volume, and organizational growth through a deliberate sequence of architectural interventions, each proportional to the observed need, without requiring a wholesale migration to a distributed architecture. G3 operationalizes this capacity by identifying module-level scale points, introducing asynchronous boundaries where load demands diverge, and abstracting infrastructure dependencies so that extraction remains a controlled option rather than an emergency.

G3 completes the Architectural Design Dimension (G1--G3). While G1 enforces modular boundaries and G2 preserves maintainability through bounded cost of change, G3 ensures that the resulting modular structure can absorb growth without collapsing into either a monolithic bottleneck or a premature microservices decomposition. Together, these three guidelines establish the structural foundation upon which the Operational Fit, Organizational Alignment, and Guideline Orientation dimensions build.

\subsection*{Intent and Rationale}

The prevailing narrative in cloud-native literature frames scalability as an inherently distributed concern: when the system must scale, it must be decomposed into independently deployable services~\cite{arya2024beyond, blinowski2022monolithic}. This framing creates a false dichotomy. Teams are implicitly told to choose between a monolith that cannot scale and microservices that can, ignoring the intermediate architectural states that a well-modularized monolith can occupy.

In practice, most early-stage systems do not face uniform scaling pressure. Load concentrates in specific modules, specific use cases exhibit disproportionate growth, and specific data domains expand faster than others. A system designed for progressive scalability acknowledges this unevenness and provides mechanisms to address it surgically, scaling the modules that need it while leaving the rest undisturbed.

G3 therefore treats scalability as a \emph{gradient} rather than a binary switch. The guideline proposes that a modular monolith can traverse a scalability spectrum through deliberate, reversible interventions:

\begin{enumerate}[itemsep=8pt,topsep=2pt]
  \item \emph{Vertical optimization within the monolith:} resource tuning, query optimization, caching, and concurrency improvements applied to specific modules without structural change.
  \item \emph{Asynchronous decoupling of hot paths:} introducing message queues or event streams between modules whose throughput requirements diverge, converting synchronous bottlenecks into buffered pipelines.
  \item \emph{Data isolation for divergent modules:} separating persistence for modules whose data access patterns, volume, or consistency requirements no longer fit a shared schema.
  \item \emph{Selective extraction of bounded contexts:} deploying individual modules as independent services only when the preceding interventions are insufficient and the operational cost is justified.
\end{enumerate}

This spectrum makes the migration to microservices an \emph{option}, not an obligation. Each step is proportional to observed need, reversible if conditions change, and grounded in the boundary enforcement (G1) and maintainability discipline (G2) already established. The key insight is that a system with enforced modular boundaries and stable contracts is \emph{already extraction-ready}; what G3 adds is the deliberate preparation of infrastructure seams, established from project inception, that make extraction low-risk when evidence warrants it.

\subsection*{Conceptual Overview}

Progressive scalability is embedded by designing modules so that growth is absorbed incrementally. Both synchronous and asynchronous communication channels are designed from inception: synchronous calls serve low-latency, consistency-critical paths, while asynchronous channels (event buses, message queues) absorb throughput divergence between modules. The choice between channels is driven by observed load patterns, not by speculative anticipation, and the transition from one to the other is a configuration change rather than a rewrite.

Critically, scalability readiness must be \emph{automatically tracked}, not manually assessed. Module-level metrics (throughput profiles, latency variance, data ownership clarity) are collected continuously and evaluated against defined thresholds. When a metric crosses its threshold, the system signals that a specific module requires a specific intervention at a specific spectrum level, removing subjectivity from scaling decisions.

\begin{itemize}[itemsep=8pt,topsep=2pt]
  \item Each module's resource consumption, throughput profile, and data growth trajectory are observable and attributable, enabling evidence-based scaling decisions.
  \item Communication between modules with divergent scaling needs can transition from synchronous to asynchronous without rewriting business logic.
  \item Persistence is designed so that schema ownership can be narrowed from shared to module-scoped without data migration crises.
  \item Infrastructure dependencies (databases, caches, queues, external APIs) are accessed through abstractions that decouple business logic from deployment topology.
\end{itemize}

\subsection*{Applicability Conditions and Scope}

G3 applies to modular monolith systems that satisfy the following conditions:
\begin{itemize}[itemsep=8pt,topsep=2pt]
  \item Module boundaries are enforced and dependencies are explicit, as established by G1.
  \item Maintainability discipline is in place, ensuring that contracts are stable and change locality is preserved, as established by G2.
  \item The system is expected to grow in load, data volume, or team size, but the timing and distribution of that growth are uncertain.
\end{itemize}

G3 does not prescribe specific cloud providers, container orchestrators, or scaling technologies. Its scope is limited to architectural preparation: the design decisions and structural properties that make scaling interventions feasible, proportional, and reversible. The guideline is agnostic to whether the system ultimately remains a monolith, becomes a set of microservices, or stabilizes at an intermediate state.


\subsection*{Objectives}

\emph{Research contributions:}
\begin{itemize}[itemsep=8pt,topsep=2pt]
  \item \emph{Formalize scalability as a gradient:} Define a progression spectrum (L0--L3) that replaces the binary monolith-or-microservices framing with a sequence of proportional, reversible interventions, each justified by evidence rather than anticipation.
  \item \emph{Quantify progression triggers:} Establish module-level metrics ($\Delta\Theta$, $\rho_{\mathrm{sync}}$, $\omega$, $\alpha$) that determine when a specific module should transition from one spectrum level to the next, removing subjectivity from scaling decisions.
  \item \emph{Provide a composite extraction readiness metric:} Synthesize boundary health (G1), maintainability signals (G2), and scalability preparation (G3) into a per-module extraction readiness score ($\varepsilon_m$) that grounds L3 decisions in architectural evidence.
\end{itemize}

\emph{Implementation objectives:}
\begin{itemize}[itemsep=8pt,topsep=2pt]
  \item \emph{Embed scalability infrastructure from inception:} Design the architecture so that the infrastructure for all spectrum levels (caching, async channels, schema isolation) exists from the first deployment, making progression a configuration change rather than a migration project.
  \item \emph{Abstract infrastructure as a replaceable dependency:} Ensure modules interact with infrastructure through ports or interfaces that can be re-bound across spectrum levels without modifying domain logic.
  \item \emph{Preserve extraction optionality:} Maintain the ability to extract any bounded context as an independent service while positioning extraction as the last resort, not the first reflex.
  \item \emph{Record progression decisions:} Document each spectrum-level transition as an Architecture Decision Record (ADR) that captures the trigger condition, the intervention applied, the expected outcome, and the rollback path.
\end{itemize}


\subsection*{Key Principles}

\begin{itemize}[itemsep=8pt,topsep=2pt]
  \item \emph{Scale where it hurts, not where it might:}
  Scaling interventions should be driven by observed bottlenecks, not by speculative anticipation. Module-level metrics (see Metrics section) provide the evidence base. Premature optimization of modules that are not under pressure introduces unnecessary complexity and operational cost.

  \item \emph{Asynchronous boundaries as scalability seams:}
  The boundary between two modules becomes a scalability seam when their throughput requirements diverge. Introducing an asynchronous channel (event bus, message queue) at this seam absorbs load spikes in the producer without propagating backpressure to the consumer, and vice versa. The key constraint is that asynchronous boundaries must respect the contracts established in G1 and the stability properties maintained by G2.

  \item \emph{Schema isolation is established from project inception:}
  Each module owns a dedicated PostgreSQL schema from the first deployment. Cross-module data access is mediated exclusively through published contracts (events or API calls), never through direct table queries. This design decision, made at project inception rather than deferred to a future migration, ensures that data isolation is a structural property of the system rather than a prerequisite to be satisfied before extraction.

  \item \emph{Infrastructure as a replaceable dependency:}
  Modules should depend on infrastructure through ports (interfaces) rather than concrete implementations. This is not an abstract design preference but a scalability prerequisite: when a module must move from an in-process event bus to a distributed message broker, or from a shared PostgreSQL instance to a dedicated read replica, the change should be confined to the infrastructure adapter, not the domain logic.

  \item \emph{Extraction is the last resort, not the first reflex:}
  Extracting a module into an independent service introduces network boundaries, distributed failure modes, deployment complexity, and operational overhead. G3 positions extraction at the end of the scalability spectrum, after vertical optimization, async decoupling, and data isolation have been exhausted or proven insufficient. This ordering preserves system simplicity for as long as possible while ensuring that extraction remains feasible when genuinely needed.
\end{itemize}


\subsection*{Implementation Mechanisms}

G3 is implemented through the following architectural mechanisms, all established from project inception:

\begin{itemize}[itemsep=8pt,topsep=2pt]
  \item \emph{Module-scoped resource profiling:} Each module's resource consumption (CPU, memory, I/O, query volume) is attributable through instrumentation or naming conventions, enabling identification of scale points without distributed tracing.

  \item \emph{Communication abstraction layer:} Inter-module communication passes through a contract-based abstraction (e.g., an event bus interface or a command dispatcher) that can be backed by in-process dispatch, an in-memory queue, or a distributed broker without changing the caller or handler.

  \item \emph{Persistence port pattern:} Each module accesses its data through repository interfaces (ports) backed by a dedicated PostgreSQL schema from project inception. The concrete implementation is injected at composition time; when a module is extracted (L3), the repository adapter is re-bound to a dedicated database instance without changing domain logic. Schema ownership is documented in the module descriptor introduced in G1.

  \item \emph{Scalability decision records:} When a module transitions between spectrum levels (e.g., from L0 to L1), the decision is recorded in an Architecture Decision Record (ADR) that captures the trigger condition, the intervention applied, the expected outcome, and the rollback path. This ensures that scaling decisions remain traceable and reversible.
\end{itemize}


\subsection*{The Progressive Scalability Spectrum}

To make the gradient concrete, G3 proposes a four-level spectrum that teams can use to assess their current position and plan their next proportional intervention. Each level builds on the previous one, and progression is driven by evidence rather than anticipation.

\begin{table}[H]
\centering
\small
\caption{Progressive Scalability Spectrum for Modular Monoliths}
\label{tab:scalability-spectrum}
\rowcolors{2}{gray!5}{white}
\begin{tabularx}{\linewidth}{p{0.06\linewidth} p{0.18\linewidth} X p{0.22\linewidth}}
\toprule
\textbf{Level} & \textbf{Intervention} & \textbf{Description} & \textbf{Trigger Condition} \\
\midrule
L0 & Vertical Optimization & Resource tuning, caching, query optimization, concurrency improvements within the monolith. No structural change. & Module-level latency or throughput degradation detected. \\
L1 & Async Decoupling & Replace synchronous inter-module calls with asynchronous channels (event bus, message queue) for modules with divergent throughput. & Synchronous calls between modules create backpressure or latency spikes under load. \\
L2 & Data Isolation & Separate module-scoped persistence (dedicated schemas, read replicas, or separate databases) for modules with divergent data access patterns. & Shared database contention, conflicting consistency requirements, or schema evolution friction. \\
L3 & Selective Extraction & Deploy a bounded context as an independent service with its own runtime, persistence, and deployment pipeline. & L0--L2 exhausted; module requires independent scaling, independent release cadence, or technology heterogeneity. \\
\bottomrule
\end{tabularx}
\end{table}

\noindent
The spectrum is not strictly linear: a team may apply L2 (data isolation) to one module while another module remains at L0. The key constraint is that each intervention at a given level should be justified by evidence that the previous level is insufficient for the module in question.


\subsection*{G3 Applied: Progressive Scalability in the Tiny Store}
\label{sec:g3-applied}

The Tiny Store reference implementation demonstrates that progressive scalability infrastructure is embedded from day one as an architectural requirement, not added later as a scaling patch. The following code listings show the actual production code that ships with the initial deployment.

\subsubsection*{L0: Vertical Optimization: Module-Scoped Caching}

Tiny Store includes a Redis-backed caching layer from day one, not as an optimization added under pressure. The \texttt{CacheService} enforces module-namespaced keys, ensuring that cache entries are isolated per bounded context and can be invalidated independently.

\begin{lstlisting}[language=TypeScript,caption={CacheService with module-namespaced keys (cache.service.ts)},label={lst:cache-service}]
export class CacheService {
  private static instance: CacheService;
  private client: Redis;
  private defaultTtl: number;
  private globalPrefix: string;

  private constructor() {
    const config = getCacheConfig();
    this.client = createRedisConnection(config);
    this.defaultTtl = config.defaultTtl || 300;
    this.globalPrefix = config.keyPrefix || 'tiny-store';
  }

  static getInstance(): CacheService {
    if (!CacheService.instance) {
      CacheService.instance = new CacheService();
    }
    return CacheService.instance;
  }

  private buildKey(module: string, key: string): string {
    return `${this.globalPrefix}:${module}:${key}`;
  }

  async get<T>(module: string, key: string): Promise<T | null> {
    const raw = await this.client.get(this.buildKey(module, key));
    if (raw === null) return null;
    return JSON.parse(raw) as T;
  }

  async set<T>(module: string, key: string, value: T,
               ttlSeconds?: number): Promise<void> {
    const fullKey = this.buildKey(module, key);
    const ttl = ttlSeconds ?? this.defaultTtl;
    await this.client.set(fullKey, JSON.stringify(value), 'EX', ttl);
  }

  async invalidatePattern(module: string,
                          pattern: string): Promise<void> {
    const keys = await this.client.keys(
      this.buildKey(module, pattern));
    if (keys.length > 0) await this.client.del(...keys);
  }
}
\end{lstlisting}

\noindent
A read-through caching decorator applies this pattern declaratively to any module method:

\begin{lstlisting}[language=TypeScript,caption={Read-through caching decorator (cache.decorator.ts)},label={lst:cache-decorator}]
export function Cacheable(
  module: string, ttlSeconds: number,
  keyFn: (...args: any[]) => string,
) {
  return function (_target: any, _propertyKey: string,
                   descriptor: PropertyDescriptor) {
    const original = descriptor.value;
    descriptor.value = async function (...args: any[]) {
      const cache = CacheService.getInstance();
      const key = keyFn(...args);
      const cached = await cache.get(module, key);
      if (cached !== null) return cached;
      const result = await original.apply(this, args);
      await cache.set(module, key, result, ttlSeconds);
      return result;
    };
    return descriptor;
  };
}
// Usage: @Cacheable('inventory', 60, (sku) => `product:${sku}`)
\end{lstlisting}

\noindent
The key design decision is that the cache layer exists from the first deployment. When vertical optimization becomes necessary (L0 trigger), the team enables caching on specific queries by adding a decorator; no infrastructure provisioning or architectural change is required.

\subsubsection*{L1: Async Decoupling: Module-Scoped Queues}

Asynchronous processing is an architectural requirement, not a scaling patch. The \texttt{QueueService} provides module-scoped BullMQ queues following the convention \texttt{module:purpose}:

\begin{lstlisting}[language=TypeScript,caption={QueueService with module-scoped queues (queue.service.ts)},label={lst:queue-service}]
export class QueueService {
  private static instance: QueueService;
  private queues: Map<string, Queue> = new Map();
  private workers: Map<string, Worker> = new Map();

  static getInstance(): QueueService {
    if (!QueueService.instance) {
      QueueService.instance = new QueueService();
    }
    return QueueService.instance;
  }

  /** Convention: `module:purpose` e.g. `orders:fulfillment` */
  createQueue(name: string): Queue {
    if (this.queues.has(name)) return this.queues.get(name)!;
    const queue = new Queue(name,
      { connection: getQueueConnection() });
    this.queues.set(name, queue);
    return queue;
  }

  async addJob<T>(queueName: string, data: T,
                  opts?: JobsOptions): Promise<Job<T>> {
    const queue = this.createQueue(queueName);
    return queue.add(queueName, data, opts);
  }

  createWorker<T>(queueName: string,
                  handler: Processor<T>): Worker<T> {
    if (this.workers.has(queueName))
      return this.workers.get(queueName)! as Worker<T>;
    const worker = new Worker<T>(queueName, handler, {
      connection: getQueueConnection(),
    });
    this.workers.set(queueName, worker);
    return worker;
  }

  async closeAll(): Promise<void> {
    for (const w of this.workers.values()) await w.close();
    for (const q of this.queues.values()) await q.close();
    this.workers.clear();
    this.queues.clear();
  }
}
\end{lstlisting}

\noindent
Listing~\ref{lst:email-job} shows a concrete use case: order confirmation emails are enqueued asynchronously with exponential backoff, decoupling the critical path (order placement) from the non-critical side effect (email delivery).

\begin{lstlisting}[language=TypeScript,caption={Order confirmation email job with async decoupling (order-confirmation-email.job.ts)},label={lst:email-job}]
const QUEUE_NAME = 'orders:confirmation-email';

export function registerOrderConfirmationWorker(): void {
  const queueService = QueueService.getInstance();
  queueService.createWorker<OrderConfirmationData>(
    QUEUE_NAME,
    async (job: Job<OrderConfirmationData>) => {
      const { orderId, customerEmail, orderTotal } = job.data;
      // In production: await emailService.send(...)
      return { sent: true, orderId };
    },
  );
}

export async function enqueueOrderConfirmation(
  data: OrderConfirmationData,
): Promise<void> {
  const queueService = QueueService.getInstance();
  await queueService.addJob(QUEUE_NAME, data, {
    attempts: 3,
    backoff: { type: 'exponential', delay: 1000 },
  });
}
\end{lstlisting}

\noindent
Because BullMQ and Redis are present from day one, the team can introduce async decoupling for any inter-module interaction by defining a new queue; no infrastructure migration is required.

\subsubsection*{L2: Data Isolation: Per-Module PostgreSQL Schemas}

Schema isolation is a design decision made at project inception. Each module owns its data from the first deployment, ensuring that extraction never requires data migration. The \texttt{schema-isolation.ts} module creates per-module PostgreSQL schemas and provides module-scoped \texttt{DataSource} connections with isolated \texttt{search\_path}:

\begin{lstlisting}[language=TypeScript,caption={Per-module PostgreSQL schema isolation (schema-isolation.ts)},label={lst:schema-isolation}]
const MODULE_SCHEMAS = [
  'orders', 'inventory', 'payments', 'shipments'
] as const;
export type ModuleName = (typeof MODULE_SCHEMAS)[number];
const moduleConnections = new Map<string, DataSource>();

export async function createAllModuleSchemas(
  dataSource: DataSource,
): Promise<void> {
  for (const mod of MODULE_SCHEMAS) {
    await dataSource.query(
      `CREATE SCHEMA IF NOT EXISTS "${mod}"`);
  }
}

export async function getModuleConnection(
  baseOptions: DataSourceOptions,
  moduleName: ModuleName,
  entities: Function[],
): Promise<DataSource> {
  if (moduleConnections.has(moduleName)) {
    const existing = moduleConnections.get(moduleName)!;
    if (existing.isInitialized) return existing;
  }
  const options: DataSourceOptions = {
    ...baseOptions,
    name: `module-${moduleName}`,
    schema: moduleName,
    entities,
    ...(baseOptions.type === 'postgres' ? {
      extra: {
        ...(baseOptions as any).extra,
        options:
          `-c search_path="${moduleName}",public`,
      },
    } : {}),
  } as DataSourceOptions;

  const ds = new DataSource(options);
  await ds.initialize();
  moduleConnections.set(moduleName, ds);
  return ds;
}
\end{lstlisting}

\noindent
Each module operates within its own PostgreSQL schema from the first \texttt{docker-compose up}. Cross-module data access is mediated through published contracts (events or API calls), never through direct table queries. When L3 extraction occurs, the module's schema migrates to a dedicated database instance, a deployment topology change, not a data migration.

\subsubsection*{Extraction Readiness Score}

The readiness score provides the evidence that drives progression decisions. Tiny Store includes an automated extraction readiness calculator that scores each module across five dimensions:

\begin{lstlisting}[language=TypeScript,caption={Extraction readiness scoring dimensions (extraction-readiness.ts)},label={lst:readiness-score}]
// Usage: npx ts-node tools/metrics/extraction-readiness.ts
//        --module orders

const checks: CheckResult[] = [
  checkCrossModuleImports(moduleName),  // 25pts
  checkEventBusUsage(moduleName),       // 20pts
  checkACLLayer(moduleName),            // 15pts
  checkDatabaseSchema(moduleName),      // 20pts
  checkVersionedEvents(moduleName),     // 20pts
];

const percentage =
  Math.round((totalScore / totalMax) * 100);

if (percentage >= 80) console.log('READY for extraction');
else if (percentage >= 60) console.log('NEARLY READY');
else if (percentage >= 40)
  console.log('PARTIAL -- significant work needed');
else console.log('NOT READY -- major refactoring required');
\end{lstlisting}

\noindent
Example output for the orders module:

\begin{verbatim}
Extraction Readiness Score: orders
==================================================
Cross-module imports [==========] 25/25
  No cross-module imports found
Event-driven communication [==========] 20/20
  Events: yes, Listeners: yes
ACL layer [==========] 15/15
  ACL adapter found for orders
Database schema isolation [==========] 20/20
  Schema 'orders' configured
Versioned event contracts [=====-----] 10/20
  Event contracts exist but no versioning
==================================================
TOTAL SCORE: 90/100 (90/100)
READY for extraction
\end{verbatim}

\noindent
The readiness score quantifies the $\varepsilon_m$ metric defined in the Metrics section. Teams run this check before any L3 extraction decision, ensuring that extraction is evidence-based rather than intuition-driven.

\subsubsection*{G3 Metrics: Tiny Store Baseline}

With the infrastructure in place, the G3 metrics can be computed from the current Tiny Store state to establish the $t_0$ reference for longitudinal tracking.

\emph{Spectrum position:} All four modules currently operate at L0 (vertical optimization). No module has triggered the L1 threshold because inter-module communication is already event-driven from inception, and no throughput divergence has been observed under the current test workload.

\emph{Cross-Module Synchronous Call Ratio ($\rho_{\mathrm{sync}}$):} All 23 inter-module interactions in the composition root flow through \texttt{eventBus.subscribe}, with zero synchronous cross-module calls at the library level. Handler instantiations in \texttt{register-listeners.ts} serve event callbacks, not direct synchronous invocations.

\begin{lstlisting}[language=bash,caption={$\rho_{\mathrm{sync}}$ computation},label={lst:g3-rho-sync}]
rho_sync = 0 / (0 + 23) = 0.0
\end{lstlisting}

\noindent
A value of 0.0 confirms that all inter-module communication is asynchronous, well below the 0.3 threshold.

\emph{Data Ownership Clarity Index ($\omega$):} Tiny Store defines 5 entities across 4 modules (Orders: 1, Inventory: 2, Payments: 1, Shipments: 1). Each entity resides exclusively within its owning module's schema. Cross-module data needs are mediated through the ACL layer (e.g., \texttt{PaymentGateway} interface in Orders), not through direct table access.

\begin{lstlisting}[language=bash,caption={$\omega$ computation},label={lst:g3-omega}]
omega = 5 / 5 = 1.0
\end{lstlisting}

\noindent
A value of 1.0 confirms unambiguous single-module ownership for all data structures.

\emph{Infrastructure Abstraction Coverage ($\alpha$):} All modules access infrastructure through the \texttt{@tiny-store/shared-infrastructure} layer (cache, queue, database, event bus). TypeORM decorators appear in entity definitions, which is expected; the access \emph{pattern} (repositories, data sources) routes through shared abstractions.

\begin{lstlisting}[language=bash,caption={$\alpha$ computation},label={lst:g3-alpha}]
alpha = 1.0
\end{lstlisting}

\emph{Extraction Readiness Score ($\varepsilon_m$):} Running the readiness calculator on the Orders module (the largest and most connected) yields 90/100, with the only deduction coming from event contracts that lack explicit versioning. All other modules score comparably or higher due to smaller surfaces.

\begin{lstlisting}[language=bash,caption={$\varepsilon_m$ for Orders},label={lst:g3-epsilon}]
epsilon_orders = 90 / 100 = 0.90
\end{lstlisting}

\vspace{0.5em}
\noindent
All G3 metrics are at healthy baseline levels: $\rho_{\mathrm{sync}} = 0.0$ (fully async), $\omega = 1.0$ (clear data ownership), $\alpha = 1.0$ (fully abstracted), $\varepsilon_{\mathrm{orders}} = 0.90$ (extraction-ready). These values confirm that the Tiny Store architecture satisfies G3 compliance from inception. The metrics establish the $t_0$ reference: any future degradation (a new synchronous cross-module call, a shared table, a direct infrastructure dependency) will be visible as a measurable regression against this baseline.

\subsection*{Common Failure Modes and Anti-Patterns}

\begin{itemize}[itemsep=8pt,topsep=2pt]
  \item \emph{Premature Distribution (``Microservices Envy''):}
  Extracting modules into services before exhausting in-process optimizations. This introduces distributed-system complexity (network latency, partial failures, eventual consistency) without evidence that distribution is necessary. The cost is disproportionate to the benefit, particularly for early-stage teams with limited operational maturity~\cite{gravanis2021dont, su2024from}.

  \item \emph{Uniform Scaling Assumption:}
  Treating all modules as having identical scaling requirements and applying the same intervention (e.g., horizontal replication of the entire monolith) uniformly. This wastes resources on modules that are not under pressure and delays targeted intervention for the modules that are.

  \item \emph{Shared Database as Implicit Coupling:}
  Allowing modules to query each other's tables directly, creating an invisible dependency that prevents data isolation (L2) and makes extraction (L3) require a coordinated schema migration. This anti-pattern often accumulates silently because it does not violate code-level boundary checks.

  \item \emph{Synchronous Call Chains Under Load:}
  Maintaining synchronous inter-module communication paths for workflows that exhibit high throughput variance. Under load, synchronous chains propagate latency and failures upstream, creating cascading degradation that appears as a system-wide outage rather than a localized bottleneck.

  \item \emph{Infrastructure Lock-In Through Concrete Dependencies:}
  Embedding infrastructure-specific code (e.g., direct database driver calls, cloud SDK invocations) in domain or application logic. This prevents the module from transitioning between spectrum levels without rewriting business logic, effectively freezing the architecture at its current scale point.
\end{itemize}


\subsection*{The Scalability Readiness Gap}

G1 and G2 ensure that module boundaries are correct and sustainable. Yet a system can satisfy both guidelines and still be \emph{unable to scale proportionally}. The gap arises because boundary enforcement and maintainability tracking say nothing about whether the architecture is \emph{prepared} for scaling interventions. A module with perfect boundary discipline and stable contracts may still share a database schema with three other modules, communicate exclusively through synchronous calls, and depend on infrastructure through concrete implementations. When load arrives, the team discovers that scaling requires a coordinated migration rather than a surgical intervention.

This is the Scalability Readiness Gap: the distance between a structurally sound modular monolith and one that can absorb growth through proportional, reversible interventions. G3's metrics close this gap by making infrastructure preparation, communication flexibility, and data ownership visible and measurable from the first deployment.


\subsection*{Metrics and Verification}

G3 metrics are designed to make scaling pressure observable at the module level and to verify that the architectural preparation for progressive scalability is in place. They complement the structural metrics defined in G1 and G2 by adding resource, throughput, and isolation dimensions.

\begin{itemize}[itemsep=8pt,topsep=2pt]
  \item \textbf{Module Throughput Profile ($\Theta_m$).} \\
  Quantifies throughput divergence across modules to identify candidates for asynchronous decoupling before bottlenecks manifest as user-visible latency~\cite{richardson2018microservices}.
  \[
    \Delta\Theta = \max_{m \in M} \Theta_m - \min_{m \in M} \Theta_m
  \]
  \emph{Target:} Monitor $\Delta\Theta$ growth; trigger L1 async decoupling when divergence exceeds 2:1 ratio between connected modules.

  \item \textbf{Module Latency Variance ($\sigma^2_{L,m}$).} \\
  Measures response time consistency within a module. High variance under load signals resource contention, inefficient queries, or synchronous dependencies on overloaded modules, making the module a candidate for L0 vertical optimization or L1 async decoupling~\cite{martin2012clean}.
  \[
    \sigma^2_{L,m} = \mathbb{E}[(L_m - \mu_{L,m})^2]
  \]
  \emph{Target:} Monitor $\sigma^2_{L,m}$ growth; investigate when variance increases $>2\times$ baseline under load.

  \item \textbf{Cross-Module Synchronous Call Ratio ($\rho_{\mathrm{sync}}$).} \\
  Quantifies the proportion of synchronous versus asynchronous inter-module interactions. Excessive synchronous communication prevents modules from scaling independently and creates cascading failure scenarios~\cite{dragoni2017microservices}.
  \[
    \rho_{\mathrm{sync}} = \frac{|I_{\mathrm{sync}}|}{|I_{\mathrm{sync}}| + |I_{\mathrm{async}}|}
  \]
  \emph{Target:} $\rho_{\mathrm{sync}} \leq 0.3$ (majority of inter-module communication asynchronous).

  \item \textbf{Data Ownership Clarity Index ($\omega$).} \\
  Measures the proportion of data structures with unambiguous single-module ownership. Shared tables create invisible coupling that prevents data isolation (L2) and blocks extraction (L3)~\cite{evans2003ddd}.
  \[
    \omega = \frac{|T_{\mathrm{single\text{-}owner}}|}{|T|}
  \]
  where $T$ is the set of all tables and $T_{\mathrm{single\text{-}owner}}$ is the subset accessed by only one module.
  \emph{Target:} $\omega = 1.0$ (all data structures have unambiguous ownership).

  \item \textbf{Infrastructure Abstraction Coverage ($\alpha$).} \\
  Quantifies the proportion of infrastructure access mediated through ports or interfaces. Direct infrastructure dependencies freeze the architecture at its current scale point, making spectrum-level transitions require code rewrites rather than configuration changes~\cite{martin2012clean}.
  \[
    \alpha = \frac{|A_{\mathrm{abstracted}}|}{|A|}
  \]
  \emph{Target:} $\alpha = 1.0$ (all infrastructure access through abstractions).

  \item \textbf{Extraction Readiness Score ($\varepsilon_m$).} \\
  Composite metric synthesizing boundary health (G1), maintainability (G2), and scalability preparation (G3) to quantify how prepared a module is for independent deployment. A high score indicates extraction would be a low-risk topology change; a low score reveals preparation debt~\cite{wolfart2021modernizing}.
  \[
    \varepsilon_m = f\!\left(C_{\mathrm{undecl}}^{(m)},\; C_{\mathrm{leak}}^{(m)},\; \omega_m,\; \alpha_m,\; \rho_{\mathrm{sync}}^{(m)}\right)
  \]
  \emph{Target:} $\varepsilon_m \geq 0.8$ before considering L3 extraction for module $m$.
\end{itemize}

\noindent
\emph{Verification strategy:} G3 metrics are tracked longitudinally alongside G1 and G2 metrics. The primary verification concern is not whether the system scales today, but whether it \emph{can} scale proportionally when needed. An increase in $\Delta\Theta$ without a corresponding decrease in $\rho_{\mathrm{sync}}$ for the affected module pair indicates that scalability preparation is lagging behind actual load growth. A declining $\omega$ indicates increasing data coupling that will block future isolation. These signals enable proactive architectural intervention before scaling becomes an emergency.

\medskip
\noindent
\textbf{Compliance summary.} G3 progressive scalability compliance holds when:
\[
  \rho_{\mathrm{sync}} \leq 0.3 \land \omega \to 1 \land \alpha = 1 \land \varepsilon_m \geq 0.8 \text{ for extraction candidates}
\]


\subsection*{Documentation Guidelines}
\begin{itemize}[itemsep=8pt,topsep=2pt]
  \item \emph{Module Scale Profile:}
  Maintain a lightweight document (or section in the module descriptor) for each module that records its current spectrum level (L0--L3), its observed throughput profile, and any known scaling constraints. This profile is updated when monitoring data changes significantly or when a spectrum-level transition occurs.

  \item \emph{Scalability ADRs:}
  Record each transition between spectrum levels as an Architecture Decision Record. The ADR should capture: the trigger condition (which metric crossed which threshold), the intervention applied, the expected outcome, the rollback path, and the actual outcome after implementation. This creates a traceable history of scaling decisions that can inform future interventions.

  \item \emph{Infrastructure Dependency Map:}
  Document which infrastructure dependencies each module uses and whether they are accessed through abstractions ($\alpha = 1$) or directly ($\alpha < 1$). This map complements the module dependency descriptor from G1 and makes infrastructure lock-in visible.
\end{itemize}

\subsection*{Tooling Capabilities Checklist}
Any open-source or proprietary tool used to support progressive scalability should address:
\begin{itemize}[itemsep=8pt,topsep=2pt]
  \item \emph{Module-scoped metrics collection:} Attribute resource consumption, latency, and throughput to individual modules within the monolith, without requiring distributed tracing infrastructure.
  \item \emph{Communication abstraction:} Provide a dispatch mechanism that supports both synchronous and asynchronous inter-module communication through the same contract interface.
  \item \emph{Schema ownership analysis:} Identify tables or collections accessed by multiple modules and quantify data ownership clarity ($\omega$).
  \item \emph{Load simulation:} Support targeted load testing of individual modules or inter-module communication paths to validate scaling interventions before production deployment.
  \item \emph{Extraction readiness assessment:} Combine G1 boundary metrics, G2 maintainability metrics, and G3 scalability metrics into a composite readiness view per module.
\end{itemize}


\subsection*{Literature Support Commentary}

The academic literature on software scalability exhibits a persistent structural gap. Empirical studies on microservices consistently provide evidence on horizontal scaling but frame distribution as a prerequisite for scalability rather than one option among several~\cite{arya2024beyond, blinowski2022monolithic, berry2024isItWorth}. Comparative analyses of performance, scalability, and cost between microservice and monolithic deployments demonstrate that the trade-offs are context-dependent, yet stop short of proposing what a team should do \emph{between} these two endpoints~\cite{jatkiewicz2023differences}. Studies that advocate for monoliths or modular monoliths acknowledge that monolithic architectures can serve moderate scaling needs but do not formalize how scaling should be approached incrementally within a monolithic boundary~\cite{montesi2021sliceable, gravanis2021dont, deLauretis2019from}. Industry experience reports reinforce this pattern: documented retreats from microservices~\cite{segment2023}, accounts of premature distribution's operational toll~\cite{auth02019}, and arguments that monoliths remain viable at significant scale~\cite{medium2019} all suggest that distribution is not a universal solution. Research on accelerating early-stage development through monolithic architectures combined with MVP practices further supports deferring distribution until evidence warrants it~\cite{lima2024accelerating}.

Two proposals come closest to the progressive scalability concept. The ``sliceable monolith'' keeps the system unified until a slice needs independent deployment~\cite{montesi2021sliceable}, but focuses on \emph{deployment granularity} (when to slice) rather than on the intermediate architectural interventions (async boundaries, data isolation, infrastructure abstraction) that precede extraction. Similarly, the ``write as a monolith, deploy as microservices'' model addresses the deployment dimension but provides no guidance on how to prepare the monolith's internal architecture for selective scaling~\cite{ghemawat2023towards}. The evolutionary architecture perspective provides the philosophical foundation, arguing that architectural properties should be preserved through fitness functions and incremental adaptation~\cite{FordParsons2017}, but does not operationalize this principle for scaling decisions at the module level.

\emph{The gap is threefold.} A systematic review of the SLR corpus reveals that no existing work provides:

\begin{enumerate}[itemsep=8pt,topsep=2pt]
  \item \emph{A formalized intermediate-state model} that defines the architectural states a modular monolith can occupy between ``monolith'' and ``microservices,'' with explicit descriptions of what each state entails structurally.
  \item \emph{Quantified progression triggers} that specify, through measurable metrics ($\rho_{\mathrm{sync}}$, $\omega$, $\alpha$, $\Delta\Theta$), when a module should transition from one scaling level to the next, replacing intuition-driven decisions with evidence-based ones.
  \item \emph{A composite extraction readiness metric} ($\varepsilon_m$) that synthesizes boundary health (G1), maintainability signals (G2), and scalability preparation (G3) into a single actionable score per module, ensuring that extraction decisions are grounded in architectural evidence rather than organizational pressure.
\end{enumerate}

G3 addresses all three gaps. The L0--L3 Progressive Scalability Spectrum (Table~\ref{tab:scalability-spectrum}) formalizes the intermediate states. The six G3 metrics define the progression triggers. The Extraction Readiness Score provides the composite decision function. Importantly, the individual techniques at each level (caching, async queues, schema isolation) are well-established patterns; G3's contribution is not the techniques themselves but the \emph{structured ordering}, the \emph{metric-driven trigger conditions}, and the \emph{verification framework} that ties them into a coherent, evidence-based progression model. This reframes scalability from a binary migration decision into a gradient of proportional, reversible interventions.

The scalability levels defined here provide the trigger criteria for G4 (Migration Readiness), which prepares individual modules for extraction when the evidence warrants it.

\subsection*{Reference Implementation: Source Files}

The code listings in this section are drawn from the Tiny Store reference implementation. The relevant source files are:

\begin{itemize}[itemsep=8pt,topsep=2pt]
  \item \texttt{libs/shared/infrastructure/src/cache/cache.service.ts}: Module-namespaced Redis caching (L0)
  \item \texttt{libs/shared/infrastructure/src/cache/cache.decorator.ts}: Read-through caching decorator (L0)
  \item \texttt{libs/shared/infrastructure/src/queue/queue.service.ts}: Module-scoped BullMQ queues (L1)
  \item \texttt{libs/modules/orders/src/jobs/order-confirmation-email.job.ts}: Async email decoupling (L1)
  \item \texttt{libs/shared/infrastructure/src/database/schema-isolation.ts}: Per-module PostgreSQL schemas (L2)
  \item \texttt{tools/metrics/extraction-readiness.ts}: Extraction readiness score calculator ($\varepsilon_m$)
\end{itemize}

\subsection*{Conclusion of the G3 Implementation}

This section demonstrated that scalability in a modular monolith is not a binary property that requires distribution to achieve, but a gradient that can be traversed through deliberate, proportional interventions. G1 ensures that module boundaries are correct; G2 ensures that they remain sustainable over time; G3 ensures that the resulting modular structure can absorb growth without requiring a wholesale architectural transformation.

The progressive scalability spectrum (L0--L3) provides a concrete decision framework: vertical optimization before async decoupling, async decoupling before data isolation, data isolation before extraction. Each level is triggered by observable metrics rather than speculative anticipation, and each intervention is reversible if conditions change. The Tiny Store reference implementation demonstrates that the infrastructure for all four levels (Redis caching, BullMQ queues, per-module PostgreSQL schemas, extraction readiness scoring) can be embedded from the first deployment, making scalability a structural property of the architecture rather than a future migration project.

With boundaries enforced (G1), maintainability preserved (G2), and scalability infrastructure prepared (G3), the architecture is structurally ready for growth. However, when a module's extraction readiness score indicates that L3 is warranted, the team needs a systematic process for preparing that module for independent deployment. G4 addresses this concern by defining the migration readiness criteria, event-driven communication contracts, and saga orchestration patterns that transform extraction from an emergency response into a controlled, evidence-based topology change.
